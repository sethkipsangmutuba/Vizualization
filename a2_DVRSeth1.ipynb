{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNlLDnnPA3/rJg82MEtXpkX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sethkipsangmutuba/Vizualization/blob/main/a2_DVRSeth1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2 Data Foundations\n",
        "\n",
        "### 2.1 Types of Data\n",
        "\n",
        "### 2.2 Structure within and between Records\n",
        "\n",
        "### 2.3 Data Preprocessing\n",
        "\n",
        "### 2.4 Data Sets Used in This Book\n",
        "\n",
        "### 2.5 Related Readings\n",
        "\n",
        "### 2.6 Exercises\n",
        "\n",
        "### 2.7 Projects\n"
      ],
      "metadata": {
        "id": "ZaqkGWAzf3Db"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2: Data Foundations\n",
        "\n",
        "## Overview\n",
        "All visualizations begin with data ‚Äî it may come from sensors, surveys, simulations, or computations.\n",
        "\n",
        "Data can be raw (unprocessed) or derived (processed: e.g., smoothed, scaled).\n",
        "\n",
        "A dataset is typically a list of n records:  \n",
        "r‚ÇÅ, r‚ÇÇ, ..., r‚Çô, each with m variables:  \n",
        "v‚ÇÅ, v‚ÇÇ, ..., v‚Çò.\n",
        "\n",
        "Variables are categorized as:\n",
        "\n",
        "- **Independent (iv):** Unaffected by others (e.g., time).\n",
        "- **Dependent (dv):** Influenced by independent variables (e.g., temperature affected by location or time).\n",
        "\n",
        "A formal structure:  \n",
        "r·µ¢ = (iv‚ÇÅ, iv‚ÇÇ, ..., iv‚Çò·µ¢, dv‚ÇÅ, dv‚ÇÇ, ..., dv‚Çòùíπ),  \n",
        "with m = m·µ¢ + mùíπ.\n",
        "\n",
        "In many datasets, the independent/dependent nature may not be known in advance.\n",
        "\n",
        "Data can also be seen as being generated by a function:\n",
        "\n",
        "- **Domain** = independent variables  \n",
        "- **Range** = dependent variables\n",
        "\n",
        "Real-world data often contains only a subset of all possible value combinations.\n",
        "\n",
        "---\n",
        "\n",
        "## 2.1 Types of Data\n",
        "\n",
        "### Two Primary Data Types:\n",
        "\n",
        "1. **Ordinal (Numeric)**  \n",
        "   - **Binary:** Only values 0 or 1  \n",
        "   - **Discrete:** Integer or limited value sets (e.g., 2, 4, 6)  \n",
        "   - **Continuous:** Real numbers in a range (e.g., [0, 5])  \n",
        "\n",
        "2. **Nominal (Non-Numeric)**  \n",
        "   - **Categorical:** From a small, finite list (e.g., red, green)  \n",
        "   - **Ranked:** Categories with a natural order (e.g., small, medium, large)  \n",
        "   - **Arbitrary:** No order, possibly infinite values (e.g., street names)  \n",
        "\n",
        "---\n",
        "\n",
        "### Scale of Measurement\n",
        "\n",
        "Variables can be evaluated based on three scale attributes:\n",
        "\n",
        "- **Ordering relation:**  \n",
        "  Exists for ranked nominal and all ordinal variables.\n",
        "\n",
        "- **Distance metric:**  \n",
        "  Applicable only to ordinal data types (e.g., temperature differences).\n",
        "\n",
        "- **Absolute zero:**  \n",
        "  Present in some ordinal variables (e.g., weight), but not others (e.g., bank balance).\n",
        "\n",
        "**Scale compatibility:**  \n",
        "When mapping data to graphics, match the variable's scale with the visual encoding (e.g., size, position).\n",
        "\n",
        "---\n",
        "\n",
        "### Operations by Data Type\n",
        "\n",
        "| Operation Type       | Nominal | Ranked Nominal | Ordinal |\n",
        "|----------------------|---------|----------------|---------|\n",
        "| Equality (=, <>)     | ‚úÖ      | ‚úÖ             | ‚úÖ      |\n",
        "| Comparison (<, >)    | ‚ùå      | ‚úÖ             | ‚úÖ      |\n",
        "| Math (+, ‚Äì, √ó, √∑)     | ‚ùå      | ‚ùå             | ‚úÖ      |\n"
      ],
      "metadata": {
        "id": "5PbnX18cgRFu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 Structure Within and Between Records\n",
        "\n",
        "Data records have both **syntax** (how they are represented) and **semantics** (how they relate within and across records).\n",
        "\n",
        "---\n",
        "\n",
        "### 2.2.1 Scalars, Vectors, and Tensors\n",
        "\n",
        "- **Scalar:** Single numerical value (e.g., age, price).  \n",
        "- **Vector:** Ordered set of scalars forming a single data item  \n",
        "  - Examples:  \n",
        "    - 2D displacement: [x, y]  \n",
        "    - RGB color: [r, g, b]  \n",
        "    - GPS: [lat, long]  \n",
        "- **Tensor:** General form including scalars and vectors  \n",
        "  - **Rank 0:** Scalar  \n",
        "  - **Rank 1:** Vector  \n",
        "  - **Rank 2+:** Matrix or higher-dimensional array  \n",
        "\n",
        "**Example:** 3√ó3 matrix as a transformation tensor in 3D space.\n",
        "\n",
        "---\n",
        "\n",
        "### 2.2.2 Geometry and Grids\n",
        "\n",
        "- **Explicit Geometry:** Coordinates given directly (e.g., longitude and latitude in temperature data).  \n",
        "- **Implied Geometry:** Grid-based spacing; position inferred from start point and step size.  \n",
        "  - Common in elevation maps and simulations.  \n",
        "\n",
        "**Coordinate Systems:**\n",
        "\n",
        "- Include Cartesian, spherical, hyperbolic  \n",
        "- Conversion to display space typically done using transformation matrices  \n",
        "\n",
        "**Irregular Geometry:**\n",
        "\n",
        "- High-density near critical areas (e.g., airflow near airplane wings)  \n",
        "- Requires explicit coordinates due to nonuniform spacing  \n",
        "- Increases computational complexity for rendering  \n",
        "\n",
        "---\n",
        "\n",
        "### 2.2.3 Other Forms of Structure\n",
        "\n",
        "- **Time (Timestamps):**  \n",
        "  - Can be absolute or relative  \n",
        "  - Uniform (e.g., sensor sampling) or nonuniform (e.g., business logs)  \n",
        "  - Varies in scale from picoseconds to centuries  \n",
        "\n",
        "- **Topology:**  \n",
        "  - Describes connectivity among records (e.g., neighbors in a mesh, links in a network)  \n",
        "  - Key for interpolation and resampling  \n",
        "  - Stored as:  \n",
        "    - Explicit links in the record  \n",
        "    - Auxiliary structures (e.g., adjacency lists)  \n",
        "\n",
        "---\n",
        "\n",
        "### Examples of Structured Data\n",
        "\n",
        "| Domain           | Structure Description                                                  |\n",
        "|------------------|------------------------------------------------------------------------|\n",
        "| MRI              | Scalar density + 3D spatial coords, 3D grid connectivity               |\n",
        "| CFD              | Displacement (3D) + spatial + time, uniform/nonuniform grid            |\n",
        "| Financial        | No geometry, multiple nominal/ordinal fields, time                     |\n",
        "| CAD              | 3D spatial + surface properties + polygon/edge connectivity            |\n",
        "| Remote Sensing   | Multi-channel, 2D/3D space + time + grid                               |\n",
        "| Census           | Mixed data types + spatial + time + implied connectivity               |\n",
        "| Social Network   | Nodes with mixed fields, connected by spatial, temporal, or group-related attributes |\n"
      ],
      "metadata": {
        "id": "dCeoBk0tih9m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3 Data Preprocessing\n",
        "\n",
        "Raw data is preferred in many fields (e.g., medical imaging) to avoid:\n",
        "\n",
        "- Loss of critical details  \n",
        "- Introduction of misleading artifacts  \n",
        "\n",
        "However, preprocessing may be essential depending on the data and visualization method.\n",
        "\n",
        "Preprocessing can expose:\n",
        "\n",
        "- Missing data  \n",
        "- Outliers  \n",
        "- Errors in computation or input  \n",
        "\n",
        "---\n",
        "\n",
        "### 2.3.1 Metadata and Statistics\n",
        "\n",
        "#### Metadata\n",
        "\n",
        "Provides important context for understanding and processing data:\n",
        "\n",
        "- Field formats  \n",
        "- Units of measurement  \n",
        "- Reference/base values  \n",
        "- Markers for missing values  \n",
        "- Measurement resolution  \n",
        "\n",
        "#### Statistical Analysis\n",
        "\n",
        "Useful for preprocessing decisions:\n",
        "\n",
        "- **Outlier Detection:** Identifies anomalous or faulty data  \n",
        "- **Cluster Analysis:** Groups similar data points  \n",
        "- **Correlation Analysis:** Detects redundancy or hidden relationships  \n",
        "\n",
        "**Basic Statistical Measures:**\n",
        "\n",
        "- **Mean ($\\mu$):**  \n",
        "  $$\n",
        "  \\mu = \\frac{1}{n} \\sum_{i=1}^{n} x_i\n",
        "  $$\n",
        "\n",
        "- **Standard Deviation ($\\sigma$):**  \n",
        "  $$\n",
        "  \\sigma = \\sqrt{ \\frac{1}{n} \\sum_{i=1}^{n} (x_i - \\mu)^2 }\n",
        "  $$\n",
        "\n",
        "#### Visual Representation\n",
        "\n",
        "- **Histogram:** Most common plot showing data distribution\n"
      ],
      "metadata": {
        "id": "xNy8RkqKi6xT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3.2 Missing Values and Data Cleansing\n",
        "\n",
        "Real-world data often contains missing or erroneous entries due to:\n",
        "\n",
        "- Sensor failure  \n",
        "- Data entry mistakes  \n",
        "- Incomplete surveys or forms  \n",
        "\n",
        "Handling such data is critical before visualization. Below are common strategies:\n",
        "\n",
        "---\n",
        "\n",
        "#### 1. Discard the Bad Record\n",
        "\n",
        "- Entire record is removed if it contains errors or missing values.  \n",
        "- **Pros:** Removes uncertainty.  \n",
        "- **Cons:** May result in large data loss; discarded records may hold valuable insight.  \n",
        "\n",
        "---\n",
        "\n",
        "#### 2. Assign a Sentinel Value\n",
        "\n",
        "- Use a unique placeholder (e.g., -5 for a 0‚Äì100 range).  \n",
        "- **Pros:** Makes problematic entries visible during visualization.  \n",
        "- **Cons:** Must exclude sentinel values from analysis to avoid skewed results.  \n",
        "\n",
        "---\n",
        "\n",
        "#### 3. Assign the Average Value\n",
        "\n",
        "- Replace missing values with the mean of that variable.  \n",
        "- **Pros:** Simple, keeps basic statistics stable.  \n",
        "- **Cons:** May hide outliers or distort true patterns in specific records.  \n",
        "\n",
        "---\n",
        "\n",
        "#### 4. Assign Value Based on Nearest Neighbor\n",
        "\n",
        "- Use the value from the most similar record (based on other variables).  \n",
        "- **Pros:** More tailored substitution than global average.  \n",
        "- **Cons:** May not be reliable if the missing variable isn‚Äôt correlated with others.  \n",
        "\n",
        "---\n",
        "\n",
        "#### 5. Compute a Substitute Value (Imputation)\n",
        "\n",
        "- Uses advanced statistical techniques to estimate missing values.  \n",
        "- **Example:** Model-based imputation by Schafer.  \n",
        "- **Goal:** Maximize statistical confidence in the substituted values.  \n",
        "\n",
        "---\n",
        "\n",
        "**Important:**  \n",
        "Any substituted value should be **flagged** as such.  \n",
        "Visualizations must reflect that these values are **estimates or placeholders**, not original data.\n"
      ],
      "metadata": {
        "id": "9cfujllqjts5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3.3 Normalization\n",
        "\n",
        "**Purpose:**  \n",
        "Normalization adjusts data values so they fit within a specific statistical or numeric range.  \n",
        "This is essential for comparing variables with different units or scales and for mapping data to visual elements like color or size.\n",
        "\n",
        "---\n",
        "\n",
        "#### Why It Matters\n",
        "\n",
        "- Visualizations often require input values to fall within a limited range.  \n",
        "- Variables with different scales can be misleading when visualized together.  \n",
        "- Ensures fair comparison across dimensions.\n",
        "\n",
        "---\n",
        "\n",
        "#### Types of Normalization\n",
        "\n",
        "**Linear normalization**  \n",
        "- Maps all values to a uniform range (e.g., 0 to 1).  \n",
        "- Common in visual encoding to evenly distribute values.  \n",
        "\n",
        "**Non-linear normalization**  \n",
        "- Used when data is unevenly distributed.  \n",
        "- Square root or logarithmic transformations spread out compressed values or compress high-value outliers.  \n",
        "- Helps improve visibility of important patterns in skewed data.\n",
        "\n",
        "**Range truncation (Bounding values)**  \n",
        "- Caps extreme values beyond a chosen threshold.  \n",
        "- Allows focus on the most relevant part of the data.  \n",
        "- Helps reduce distortion caused by outliers.\n",
        "\n",
        "---\n",
        "\n",
        "#### Quantiles in Normalization\n",
        "\n",
        "- Boundaries for truncation can be set using **quantiles**.  \n",
        "- For instance, excluding the top and bottom 1% of values ensures the majority is emphasized.\n",
        "\n",
        "---\n",
        "\n",
        "### 2.3.4 Segmentation\n",
        "\n",
        "**Purpose:**  \n",
        "Segmentation divides data into meaningful groups or categories.  \n",
        "It identifies patterns, simplifies interpretation, and improves visualization.\n",
        "\n",
        "---\n",
        "\n",
        "#### Examples of Segmentation\n",
        "\n",
        "- In medical imaging, different tissues (like bone or muscle) are extracted from grayscale MRI data.  \n",
        "- In geographic or demographic data, regions or populations are grouped based on common attributes.\n",
        "\n",
        "---\n",
        "\n",
        "#### Types of Segmentation\n",
        "\n",
        "**Simple segmentation**  \n",
        "- Data is divided based on predefined value ranges.\n",
        "\n",
        "**Probabilistic segmentation**  \n",
        "- Assigns likelihoods to data points for belonging to various categories, adding nuance.\n",
        "\n",
        "---\n",
        "\n",
        "#### Common Issues\n",
        "\n",
        "**Undersegmentation:**  \n",
        "Important differences are lost because different types are grouped together.\n",
        "\n",
        "**Oversegmentation:**  \n",
        "Too many small, insignificant regions reduce clarity.\n",
        "\n",
        "---\n",
        "\n",
        "#### Refinement: Split-and-Merge Approach\n",
        "\n",
        "This is an iterative method to improve segmentation:\n",
        "\n",
        "- Similar regions are **merged** based on a similarity threshold.  \n",
        "- Non-uniform regions are **split** to increase classification accuracy.  \n",
        "- The process repeats until no further merging or splitting is needed.\n",
        "\n",
        "---\n",
        "\n",
        "#### Key Factors in Refinement\n",
        "\n",
        "- **Similarity:** Often assessed by comparing average values between regions.  \n",
        "- **Homogeneity:** Evaluated using data distribution within a region.  \n",
        "- **Region Splitting:** Based on identifying internal variation and separating parts accordingly.\n",
        "\n",
        "---\n",
        "\n",
        "#### Avoiding Infinite Loops\n",
        "\n",
        "Refinement must be managed carefully to prevent repeated splitting and merging of the same regions.  \n",
        "This is typically handled by **gradually tightening or relaxing the thresholds**.\n"
      ],
      "metadata": {
        "id": "eob6EVZEkXN5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3.5 Sampling and Subsetting\n",
        "\n",
        "---\n",
        "\n",
        "#### Overview\n",
        "\n",
        "Sampling and subsetting are vital data preprocessing steps used to adapt data resolution, manage large datasets, and reduce complexity in visualization tasks.\n",
        "\n",
        "---\n",
        "\n",
        "### 1. Sampling and Resampling\n",
        "\n",
        "**Purpose:**  \n",
        "Transform a dataset from one spatial resolution to another ‚Äî commonly needed when resizing images or estimating values between sparse data points.\n",
        "\n",
        "---\n",
        "\n",
        "#### Interpolation\n",
        "\n",
        "Interpolation estimates values between known data points under the assumption that the data represent a discrete sampling of a continuous phenomenon.\n",
        "\n",
        "- **Linear Interpolation**  \n",
        "  Estimates intermediate values along a straight line between two known points.  \n",
        "  Simple but may result in abrupt changes across boundaries.\n",
        "\n",
        "- **Bilinear Interpolation**  \n",
        "  Extends linear interpolation to two dimensions (e.g., image grids).  \n",
        "  Useful for estimating values at fractional coordinates between grid points.\n",
        "\n",
        "- **Nonlinear Interpolation**  \n",
        "  Uses higher-order polynomial curves (like splines) for smoother transitions.  \n",
        "  *Catmull-Rom* curves are often employed because they pass through known data points and provide continuity.\n",
        "\n",
        ">  **Nonlinear methods** are preferred when smooth transitions between data points are critical, such as in image smoothing or surface modeling.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. Subsampling and Data Reduction\n",
        "\n",
        "When datasets are too dense or large:\n",
        "\n",
        "- **Subsampling** reduces data volume by selecting representative points.\n",
        "\n",
        "**Methods:**\n",
        "- Regular sampling (e.g., every *n*th point)  \n",
        "- Averaging neighborhoods  \n",
        "- Selecting medians or random values  \n",
        "- Domain-specific feature preservation\n",
        "\n",
        ">  **Caution:** Na√Øve subsampling may miss important features like small objects or sharp boundaries.\n",
        "\n",
        "---\n",
        "\n",
        "### 3. Data Subsetting\n",
        "\n",
        "**Purpose:** Focus analysis or visualization on relevant data portions.\n",
        "\n",
        "#### Query-based Subsetting\n",
        "- Filters data using conditions (e.g., time ranges, thresholds)  \n",
        "- Efficient ‚Äî avoids loading entire datasets  \n",
        "- Suitable for structured or database-driven tasks\n",
        "\n",
        "#### Interactive Subsetting\n",
        "- User visually selects portions of data (e.g., brushing, highlighting)  \n",
        "- More flexible and exploratory  \n",
        "- Allows intuitive filtering during visual exploration\n",
        "\n",
        "---\n",
        "\n",
        "### Post-Subset Actions\n",
        "\n",
        "- **Delete:** Remove irrelevant data  \n",
        "- **Mask:** Hide everything except the selected subset  \n",
        "- **Highlight:** Emphasize chosen parts for comparison\n",
        "\n",
        "---\n",
        "\n",
        "### Key Takeaways\n",
        "\n",
        "- Sampling and interpolation are crucial for handling sparse or differently scaled data.  \n",
        "- Subsetting simplifies large datasets for analysis without overwhelming the user or the visualization system.  \n",
        "- A **balance between accuracy and efficiency** is needed to maintain data fidelity while reducing complexity.\n"
      ],
      "metadata": {
        "id": "ahHuRvzVk7ui"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3.6 Dimension Reduction\n",
        "\n",
        "When data has many dimensions ‚Äî more than a visualization technique or human cognition can effectively handle ‚Äî we use **dimension reduction** to simplify the data while preserving as much information as possible.\n",
        "\n",
        "This process helps highlight **patterns, clusters, and outliers** without needing to display every variable.\n",
        "\n",
        "---\n",
        "\n",
        "#### Manual and Automated Techniques\n",
        "\n",
        "- **Manual Selection**: The user chooses which variables to retain based on domain knowledge.\n",
        "\n",
        "- **Automated Methods**:\n",
        "\n",
        "  - **Principal Component Analysis (PCA)**  \n",
        "    A linear technique that creates new axes (*principal components*) as combinations of the original dimensions.  \n",
        "    These new axes are ranked by how much **variance** they explain in the data.  \n",
        "    üìñ [More on PCA](https://en.wikipedia.org/wiki/Principal_component_analysis)\n",
        "\n",
        "  - **Multidimensional Scaling (MDS)**  \n",
        "    Places data in a lower-dimensional space to match high-dimensional distances.  \n",
        "    üìñ [More on MDS](https://en.wikipedia.org/wiki/Multidimensional_scaling)\n",
        "\n",
        "  - **Kohonen Self-Organizing Maps (SOMs)**  \n",
        "    Unsupervised neural networks that map high-dimensional data to a 2D grid while preserving topology.  \n",
        "    üìñ [More on SOMs](https://en.wikipedia.org/wiki/Self-organizing_map)\n",
        "\n",
        "  - **Local Linear Embedding (LLE)**  \n",
        "    A nonlinear method that preserves local structure during reduction.  \n",
        "    üìñ [More on LLE](https://en.wikipedia.org/wiki/Locally_linear_embedding)\n",
        "\n",
        "---\n",
        "\n",
        "#### PCA: How It Works\n",
        "\n",
        "1. Subtract the mean from each data dimension.  \n",
        "2. Compute the **covariance matrix**.  \n",
        "3. Calculate **eigenvectors** and **eigenvalues**.  \n",
        "4. Sort eigenvectors by descending eigenvalue magnitude.  \n",
        "5. Choose top $k$ eigenvectors as new axes.  \n",
        "6. Project the data onto these axes.\n",
        "\n",
        "> PCA is widely used for efficient linear transformation.  \n",
        "> Example: The **Iris dataset** often demonstrates class clustering in 2D after PCA.\n",
        "\n",
        "---\n",
        "\n",
        "#### MDS: How It Works\n",
        "\n",
        "1. Calculate all pairwise distances in the high-dimensional space.  \n",
        "2. Randomly initialize 2D/3D point positions.  \n",
        "3. Iteratively adjust positions to minimize **stress** (difference between actual and target distances).  \n",
        "4. Stop when improvement is minimal.\n",
        "\n",
        "> ‚ö†Ô∏è MDS is **sensitive to initialization** and may need repeated runs or enhancements like [simulated annealing](https://en.wikipedia.org/wiki/Simulated_annealing) to avoid local minima.\n",
        "\n",
        "---\n",
        "\n",
        "### 2.3.7 Mapping Nominal Dimensions to Numbers\n",
        "\n",
        "Nominal variables (e.g., car brands, model names) lack inherent order.  \n",
        "**Mapping them to numbers or coordinates must avoid implying false relationships.**\n",
        "\n",
        "#### Strategies\n",
        "\n",
        "- **Direct Labeling**  \n",
        "  Best for small datasets but can become cluttered.\n",
        "\n",
        "- **Symbols or Colors**  \n",
        "  Use distinct markers or hues without implying numerical order.\n",
        "\n",
        "- **Statistical Similarity**  \n",
        "  Use numeric attributes to group similar nominal values.  \n",
        "  Then apply methods like **MDS** to assign positions.\n",
        "\n",
        "- **Correspondence Analysis**  \n",
        "  A technique like PCA, but for **categorical data**.  \n",
        "  üìñ [More on Correspondence Analysis](https://en.wikipedia.org/wiki/Correspondence_analysis)\n",
        "\n",
        "---\n",
        "\n",
        "### 2.3.8 Aggregation and Summarization\n",
        "\n",
        "Large or dense datasets benefit from **aggregation**, which simplifies data by grouping similar records and summarizing them.\n",
        "\n",
        "---\n",
        "\n",
        "#### Key Concepts\n",
        "\n",
        "- **Clustering**:  \n",
        "  Group points by similarity using:\n",
        "\n",
        "  - Bottom-up (agglomerative) merging  \n",
        "  - Top-down (divisive) partitioning  \n",
        "  - Split-and-merge methods  \n",
        "  üìñ [More on clustering](https://en.wikipedia.org/wiki/Cluster_analysis)\n",
        "\n",
        "- **Summary Statistics**:  \n",
        "  Compute measures like means, variances, and counts per group.\n",
        "\n",
        "---\n",
        "\n",
        "#### Visualization of Aggregates\n",
        "\n",
        "- Show **summary shapes or symbols** for each cluster  \n",
        "- Allow **drill-down** to explore internal variation  \n",
        "- Avoid **over-summarizing**, which can hide meaningful patterns\n",
        "\n",
        ">  Example: In the **Iris dataset**, parallel coordinate plots with aggregation help spot dominant clusters, while still allowing detailed exploration.\n"
      ],
      "metadata": {
        "id": "jqZ2H9Wzlgme"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3.9 Smoothing and Filtering\n",
        "\n",
        "**Purpose**  \n",
        "- Reduce noise and blur sharp changes in data.  \n",
        "- Common in **signal** and **time-series** processing.\n",
        "\n",
        "---\n",
        "\n",
        "####  Convolution (Weighted Averaging)\n",
        "\n",
        "Smooths data using values from neighboring points.\n",
        "\n",
        "**1D Example:**\n",
        "\n",
        "$$\n",
        "p_i' = \\frac{1}{4}p_{i-1} + \\frac{1}{2}p_i + \\frac{1}{4}p_{i+1}\n",
        "$$\n",
        "\n",
        "Used for sliding-window smoothing. The weights define the **filter kernel**.\n",
        "\n",
        "---\n",
        "\n",
        "#### Exponential Smoothing\n",
        "\n",
        "Gives more weight to **recent values** than older ones.\n",
        "\n",
        "**Formula:**\n",
        "\n",
        "$$\n",
        "s_0 = x_0,\\quad s_t = \\alpha x_{t-1} + (1 - \\alpha)s_{t-1}\n",
        "$$\n",
        "\n",
        "Where:  \n",
        "- $x_t$ is the observed value at time $t$  \n",
        "- $s_t$ is the smoothed value  \n",
        "- $\\alpha$ is the **smoothing factor**, $0 < \\alpha < 1$\n",
        "\n",
        "---\n",
        "\n",
        " **Further Reading**  \n",
        "- [Smoothing (Wikipedia)](https://en.wikipedia.org/wiki/Smoothing)  \n",
        "- [Exponential Smoothing](https://en.wikipedia.org/wiki/Exponential_smoothing)  \n",
        "- [Convolution](https://en.wikipedia.org/wiki/Convolution)\n",
        "\n",
        "---\n",
        "\n",
        "### 2.3.10 Raster-to-Vector Conversion\n",
        "\n",
        " **Purpose**  \n",
        "Transform raster images (pixel-based) into vector graphics (points, lines, shapes).\n",
        "\n",
        "---\n",
        "\n",
        " **Why Convert?**\n",
        "\n",
        "- More compact and scalable representation  \n",
        "- Easier **geometric transformation** (e.g., rotation, scaling)  \n",
        "- Better for **analysis**, **comparison**, and **modeling**\n",
        "\n",
        "---\n",
        "\n",
        " **Techniques**\n",
        "\n",
        "- **Thresholding**  \n",
        "  Segment the image by applying intensity cutoffs.  \n",
        "  üìñ [Thresholding (Image Processing)](https://en.wikipedia.org/wiki/Thresholding_(image_processing))\n",
        "\n",
        "- **Region Growing**  \n",
        "  Expand from seed pixels by adding neighboring pixels with similar values.  \n",
        "  üìñ [Region Growing](https://en.wikipedia.org/wiki/Region_growing)\n",
        "\n",
        "- **Boundary Detection (Edge Detection)**  \n",
        "  Detects edges using filters like **Sobel** or **Canny**.  \n",
        "  üìñ [Edge Detection](https://en.wikipedia.org/wiki/Edge_detection)  \n",
        "  üìñ [Kernel in Image Processing](https://en.wikipedia.org/wiki/Kernel_(image_processing))\n",
        "\n",
        "- **Thinning (Skeletonization)**  \n",
        "  Reduces thick structures to 1-pixel-wide centerlines.  \n",
        "  üìñ [Topological Skeleton](https://en.wikipedia.org/wiki/Topological_skeleton)\n",
        "\n",
        "---\n",
        "\n",
        "**Related Topics**\n",
        "\n",
        "- [Vectorization (Image Tracing)](https://en.wikipedia.org/wiki/Vectorization_(image_tracing))  \n",
        "- [Image Processing Overview](https://en.wikipedia.org/wiki/Image_processing)\n"
      ],
      "metadata": {
        "id": "zoxUvtb0mO7O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3.11 Summary of Data Preprocessing\n",
        "\n",
        "Data preprocessing steps such as smoothing, normalization, or transformation improve visualization quality and facilitate discovery ‚Äî but they also **modify the raw data**.\n",
        "\n",
        "---\n",
        "\n",
        " **Why it matters:**\n",
        "\n",
        "- Users should be informed of any preprocessing to avoid misinterpretation.\n",
        "- Lack of transparency can lead to **false conclusions** (see Chapter 13).\n",
        "\n",
        "---\n",
        "\n",
        "### 2.4 Data Sets Used in This Book\n",
        "\n",
        "A wide variety of datasets are used to demonstrate visualizations throughout the book. Most are available either on the book‚Äôs companion site or from open data repositories.\n",
        "\n",
        "---\n",
        "\n",
        " **Public Data Portals**\n",
        "\n",
        "- [U.S. Open Data](https://www.data.gov)  \n",
        "- [European Union Open Data](https://open-data.europa.eu)\n",
        "\n",
        "---\n",
        "\n",
        " **Sample Data Sets**\n",
        "\n",
        "- **DJIA** (`djia-100.xls`)  \n",
        "   100+ years of Dow Jones daily closings  \n",
        "   [Source](https://www.analyzeindices.com/dow-jones-history.shtml)\n",
        "\n",
        "- **Colorado Elevation** (`colorado_elev.vit`)  \n",
        "   Elevation grid of Colorado  \n",
        "   [Source](https://opendx.org)\n",
        "\n",
        "- **UVW Flow Field** (`uvw.dat`)  \n",
        "   3D vector field of turbulent flow  \n",
        "   Courtesy: Drs. Jiacai Lu and Gretar Tryggvason  \n",
        "   [Source](https://www.me.wpi.edu/Tryggvason)\n",
        "\n",
        "- **U.S. City Temperatures** (`city_temp.xls`)  \n",
        "   Average January temperatures for 56 U.S. cities  \n",
        "   [Source](https://lib.stat.cmu.edu/datasets/city-temp)\n",
        "\n",
        "- **CT Head MRI** (`CThead.zip`)  \n",
        "   3D medical scan (256√ó256√ó113)  \n",
        "   [Source](https://graphics.stanford.edu/data/voldata/)\n",
        "\n",
        "- **Miscellaneous Excel Files** (`cars.xls`, `detroit.xls`, `cereal.xls`)  \n",
        "   Multivariate, nonspatial data sets  \n",
        "   [Source](https://lib.stat.cmu.edu)\n",
        "\n",
        "- **Health-Related Data**  \n",
        "   UNICEF indicators, CDC obesity rates  \n",
        "   [Source](https://www.openindicators.org)\n",
        "\n",
        "- **VAST Challenge Data**  \n",
        "   Synthetic, complex multivariate data with embedded truth  \n",
        "   [Source](https://hcil.umd.edu/localphp/hcil/vast/archive/index.php)\n",
        "\n",
        "- **U.S. County Census**  \n",
        "   Age, race, household composition  \n",
        "   [Raw Data](https://www.census.gov)  \n",
        "   [Cleaned Version](https://www.openindicators.org/data)\n",
        "\n",
        "- **Iris Data** (`iris.csv`)  \n",
        "   Classic flower measurement dataset  \n",
        "   [Source](https://archive.ics.uci.edu/ml/datasets/Iris)\n",
        "\n",
        "---\n",
        "\n",
        "### 2.5 Related Readings\n",
        "\n",
        " **Additional references for deepening understanding:**\n",
        "\n",
        "- Preprocessing theory: ‚ÄúData Preprocessing‚Äù, in [352]\n",
        "- Dimension reduction: PCA, manifold models ([53])\n",
        "\n",
        "---\n",
        "\n",
        " **File Format Encyclopedias**\n",
        "\n",
        "- Brown et al. for image formats  \n",
        "- Older archive: [Wotsit](https://www.wotsit.org)\n",
        "\n",
        "---\n",
        "\n",
        " **Online Data Repositories**\n",
        "\n",
        "- [StatLib (CMU)](https://lib.stat.cmu.edu)  \n",
        "- [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/index.php)  \n",
        "- [NOAA Climate Data](https://www.ncei.noaa.gov)  \n",
        "- [VAST Archives](https://hcil.umd.edu/localphp/hcil/vast/archive/index.php)\n",
        "\n",
        "---\n",
        "\n",
        "### 2.6 Exercises\n",
        "\n",
        "Engage students with reflective and applied thinking:\n",
        "\n",
        "- Identify datasets with or without:\n",
        "  - Ordering  \n",
        "  - Distance metric  \n",
        "  - Absolute zero\n",
        "\n",
        "- Distinguish between **attribute** vs. **value** with examples.\n",
        "\n",
        "- Compare missing data strategies:\n",
        "  - Delete rows  \n",
        "  - Use placeholders like -999  \n",
        "  - Mean substitution  \n",
        "  - Nearest-neighbor fill\n",
        "\n",
        "- Search public data repositories and analyze their types and structure.\n",
        "\n",
        "- Extract data from newspapers ‚Äî by section ‚Äî and design potential datasets.\n",
        "\n",
        "- Identify 10+ sources of everyday data (e.g., nutrition labels, phone step counter).\n",
        "\n",
        "- Download recent temperatures and apply **smoothing (convolution)**.\n",
        "\n",
        "---\n",
        "\n",
        "### 2.7 Projects\n",
        "\n",
        "Projects for deeper, hands-on application:\n",
        "\n",
        "- **Resample 3D scalar field**  \n",
        "  üì• Input: dimensions (height, width, depth)  \n",
        "  ‚û°Ô∏è Output: resampled volume\n",
        "\n",
        "- **Bin categorization strategies**  \n",
        "  - Uniform bin width  \n",
        "  - Uniform bin count  \n",
        "  - Gap-based splits\n",
        "\n",
        "- **Normalization Program**\n",
        "  - Normalize to range $$[0, 1]$$  \n",
        "  - Normalize to mean $$= 0$$ and standard deviation $$= 1$$  \n",
        "  - Map to integer range $$[0, 255]$$\n",
        "\n",
        "- **Missing Value Imputation (Schafer‚Äôs Model)**\n",
        "  - Use R: [https://www.r-project.org](https://www.r-project.org)  \n",
        "  - Compare with your own implementation\n",
        "\n",
        "- **PCA Implementation on Iris Data**\n",
        "  - Identify principal components  \n",
        "  - Visualize results using **dimensional reduction**\n"
      ],
      "metadata": {
        "id": "TLTTNoyHnncn"
      }
    }
  ]
}